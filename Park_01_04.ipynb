{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Park_01_04.ipynb",
      "provenance": [],
      "mount_file_id": "1YBiel60iH7mHEnh2bNMAY5fxM1gnpkIv",
      "authorship_tag": "ABX9TyNrGhl82cQ+SwG4zJia3+aB",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Zaxx48/Mask_RCNN/blob/master/Park_01_04.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2-cUYCos8oSZ",
        "outputId": "d3e386ee-3676-434d-ea33-ca70703cc9a8"
      },
      "source": [
        "import os\n",
        "os.chdir(\"/content/drive/My Drive/AK49/Mask_RCNN/\")\n",
        "\n",
        "%tensorflow_version 1.x\n",
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "import mrcnn.config\n",
        "import mrcnn.utils\n",
        "from mrcnn.model import MaskRCNN\n",
        "from pathlib import Path\n",
        "import tensorflow.keras.preprocessing.image as imgpros\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bWgHrmEW91uJ",
        "outputId": "2b9a832d-c5b1-4414-9bac-53808e2107d7"
      },
      "source": [
        "class MaskRCNNConfig(mrcnn.config.Config):\n",
        "    NAME = \"coco_pretrained_model_config\"\n",
        "    IMAGES_PER_GPU = 1\n",
        "    GPU_COUNT = 1\n",
        "    NUM_CLASSES = 1 + 80  # COCO dataset has 80 classes + one background class\n",
        "    DETECTION_MIN_CONFIDENCE = 0.6\n",
        "\n",
        "\n",
        "# Filter a list of Mask R-CNN detection results to get only the detected cars / trucks\n",
        "def get_car_boxes(boxes, class_ids):\n",
        "    car_boxes = []\n",
        "    for i, box in enumerate(boxes):\n",
        "        # If the detected object isn't a car / truck, skip it\n",
        "        if class_ids[i] in [3, 8, 6]:\n",
        "            car_boxes.append(box)\n",
        "    return np.array(car_boxes)\n",
        "\n",
        "\n",
        "# Root directory of the project\n",
        "ROOT_DIR = Path(\"/content/drive/MyDrive/AK49/Mask_RCNN\")\n",
        "\n",
        "# Directory to save logs and trained model\n",
        "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
        "\n",
        "# Local path to trained weights file\n",
        "COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n",
        "\n",
        "# Download COCO trained weights from Releases if needed\n",
        "if not os.path.exists(COCO_MODEL_PATH):\n",
        "    mrcnn.utils.download_trained_weights(COCO_MODEL_PATH)\n",
        "# Create a Mask-RCNN model in inference mode\n",
        "model = MaskRCNN(mode=\"inference\", model_dir=MODEL_DIR, config=MaskRCNNConfig())\n",
        "\n",
        "# Load pre-trained model\n",
        "model.load_weights(COCO_MODEL_PATH, by_name=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/AK49/Mask_RCNN/mrcnn/model.py:399: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /content/drive/My Drive/AK49/Mask_RCNN/mrcnn/model.py:423: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "box_ind is deprecated, use box_indices instead\n",
            "WARNING:tensorflow:From /content/drive/My Drive/AK49/Mask_RCNN/mrcnn/model.py:720: The name tf.sets.set_intersection is deprecated. Please use tf.sets.intersection instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/AK49/Mask_RCNN/mrcnn/model.py:722: The name tf.sparse_tensor_to_dense is deprecated. Please use tf.sparse.to_dense instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/AK49/Mask_RCNN/mrcnn/model.py:772: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQSHwFEe936x",
        "outputId": "a3de6a92-591b-4376-9f3c-6454697d06ec"
      },
      "source": [
        "# Location of parking spaces\n",
        "file = open(\"/content/drive/MyDrive/AK49/Mask_RCNN/car_boxes/file_mov31.txt\", \"r\")\n",
        "#cambiar file por un archivo de texto con coordenadas\n",
        "parkinglot_boxes = file.read()\n",
        "parkarr = parkinglot_boxes.split('\\n')\n",
        "parkarr.pop(0)\n",
        "print(parkarr)\n",
        "pinned_car_boxes = []\n",
        "for box in parkarr:\n",
        "    box = box.split(' ')\n",
        "    box[0] = int(box[0])\n",
        "    box[1] = int(box[1])\n",
        "    box[2] = int(box[2])\n",
        "    box[3] = int(box[3])\n",
        "    pinned_car_boxes.append([box[1], box[0], box[3], box[2]])\n",
        "pinned_car_boxes = np.array(pinned_car_boxes)\n",
        "print(pinned_car_boxes)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['14 791 266 881', '302 788 539 878', '617 797 809 899', '884 791 1079 893', '1139 779 1343 878', '1397 794 1598 875', '1646 782 1841 863', '5 656 224 728', '245 656 440 743', '473 668 644 749', '698 665 881 746', '932 677 1112 758', '1139 671 1316 752', '1384 683 1556 758', '1619 692 1793 776', '1739 656 1913 758', '21 504 91 517', '117 511 186 529', '234 514 306 546', '360 523 481 541', '544 519 655 543', '700 522 786 552', '846 525 946 558', '997 528 1111 561', '1167 528 1270 562', '1317 529 1432 564', '1468 532 1587 571', '1614 529 1708 592', '1800 528 1884 582']\n",
            "[[ 791   14  881  266]\n",
            " [ 788  302  878  539]\n",
            " [ 797  617  899  809]\n",
            " [ 791  884  893 1079]\n",
            " [ 779 1139  878 1343]\n",
            " [ 794 1397  875 1598]\n",
            " [ 782 1646  863 1841]\n",
            " [ 656    5  728  224]\n",
            " [ 656  245  743  440]\n",
            " [ 668  473  749  644]\n",
            " [ 665  698  746  881]\n",
            " [ 677  932  758 1112]\n",
            " [ 671 1139  752 1316]\n",
            " [ 683 1384  758 1556]\n",
            " [ 692 1619  776 1793]\n",
            " [ 656 1739  758 1913]\n",
            " [ 504   21  517   91]\n",
            " [ 511  117  529  186]\n",
            " [ 514  234  546  306]\n",
            " [ 523  360  541  481]\n",
            " [ 519  544  543  655]\n",
            " [ 522  700  552  786]\n",
            " [ 525  846  558  946]\n",
            " [ 528  997  561 1111]\n",
            " [ 528 1167  562 1270]\n",
            " [ 529 1317  564 1432]\n",
            " [ 532 1468  571 1587]\n",
            " [ 529 1614  592 1708]\n",
            " [ 528 1800  582 1884]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J4IWX8-v-RVR"
      },
      "source": [
        "# Video file or camera to process - set this to 0 to use your webcam instead of a video file\n",
        "VIDEO_SOURCE = os.path.join(ROOT_DIR,\"/test_videos/DJI_0031.MOV\")\n",
        "\n",
        "# Load the video file we want to run detection on\n",
        "video_capture = cv2.VideoCapture(VIDEO_SOURCE)\n",
        "\n",
        "# FPS calculate and timing to frames\n",
        "seconds = 3\n",
        "fps = video_capture.get(cv2.CAP_PROP_FPS)  # Gets the frames per second\n",
        "multiplier = int(fps * seconds)\n",
        "\n",
        "while video_capture.isOpened():\n",
        "    success, frame = video_capture.read()\n",
        "    if success:\n",
        "        frameId = int(round(video_capture.get(1)))\n",
        "        cv2.imwrite('test_images/new'+ str(frameId)+'.jpg', frame)\n",
        "        if frameId % multiplier == 0:\n",
        "            #rgb_image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "            rgb_image = imgpros.img_to_array(frame)\n",
        "            # Run the image through the Mask R-CNN model to get results.\n",
        "            \n",
        "            results = model.detect([rgb_image], verbose=0)\n",
        "           \n",
        "            # Mask R-CNN assumes we are running detection on multiple images.\n",
        "            # We only passed in one image to detect, so only grab the first result.\n",
        "            r = results[0]\n",
        "            parked_car_boxes = get_car_boxes(r['rois'], r['class_ids'])\n",
        "\n",
        "            overlaps = mrcnn.utils.compute_overlaps(pinned_car_boxes, parked_car_boxes)\n",
        "            # overlaps = overlaps.transpose()\n",
        "\n",
        "            free_space = False\n",
        "            # for parking_area, overlap_areas in zip(parked_car_boxes, overlaps):\n",
        "            for parking_area, overlap_areas in zip(pinned_car_boxes, overlaps):\n",
        "                max_IoU_overlap = np.max(overlap_areas)\n",
        "                # x1, y1 ,x2, y2 = parking_area\n",
        "                y1, x1, y2, x2 = parking_area\n",
        "                if max_IoU_overlap < 0.25:\n",
        "                    # Parking space not occupied! Draw a green box around it\n",
        "                    cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 3)\n",
        "                    # Flag that we have seen at least one open space\n",
        "                    free_space = True\n",
        "                else:\n",
        "                    # Parking space is still occupied - draw a red box around it\n",
        "                    cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 0, 255), 3)\n",
        "\n",
        "                font = cv2.FONT_HERSHEY_DUPLEX\n",
        "                cv2.putText(frame, f\"{max_IoU_overlap:0.2}\", (x1 + 6, y2 - 6), font, 0.3, (255, 255, 255))\n",
        "            # for box in parked_car_boxes:\n",
        "            #     print(\"Car: \", box)\n",
        "            #\n",
        "            #     y1, x1, y2, x2 = box\n",
        "            #\n",
        "            #     # Draw the box\n",
        "            #     cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 0, 0), 2)\n",
        "            cv2_imshow(frame)\n",
        "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "                break\n",
        "    else: break\n",
        "video_capture.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0s6GP0qDcQoz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}